import React, { useState, useRef, useEffect } from 'react';
import { Send, Bot, User, Sparkles, AlertCircle } from 'lucide-react';
import { Button } from './ui/Button';
import { CodePreview } from './CodePreview';
import { cn } from '@/lib/utils';
import { useExtension } from '@/hooks/useExtension';
import { conversationHistory } from '@/services/conversationHistory';

export function ChatInterface({ autoGenerateType = null, onBack = null }) {
    // Format message content with custom styling for headers
    const formatMessageContent = (content) => {
        if (!content) return null;

        const lines = content.split('\n');
        return lines.map((line, index) => {
            // Check if line is a header (contains ** markers)
            if (line.includes('**') && line.includes(':')) {
                const headerText = line.replace(/\*\*/g, '').trim();
                return (
                    <div key={index} className="text-base font-bold text-primary mt-2 mb-1">
                        {headerText}
                    </div>
                );
            }
            // Regular line
            return <div key={index}>{line || '\u00A0'}</div>;
        });
    };

    const [messages, setMessages] = useState([
        {
            id: 1,
            role: 'assistant',
            content: "Hi! I'm RepoSpector Copilot. I can help you with:\n\n**Test Generation:**\n\nâ€¢ generate unit tests\n\nâ€¢ create integration tests\n\nâ€¢ add pytest tests\n\n**Code Analysis:**\n\nâ€¢ explain this code\n\nâ€¢ find issues in this code\n\nâ€¢ suggest improvements\n\nâ€¢ how does this function work?\n\nâ€¢ what are potential bugs?\n\nWhat can I help you with?",
            type: 'text'
        }
    ]);
    const [input, setInput] = useState('');
    const messagesEndRef = useRef(null);
    const { sendMessage, initRAG, indexRepo, isLoading, error } = useExtension();
    const [isIndexing, setIsIndexing] = useState(false);
    const [embeddingProvider, setEmbeddingProvider] = useState('openai'); // 'openai' or 'transformers' (transformers not supported in service worker)
    const [modelLoading, setModelLoading] = useState(false);
    const [streamingMessageId, setStreamingMessageId] = useState(null);
    const [autoGenerated, setAutoGenerated] = useState(false);
    const [streamingPhase, setStreamingPhase] = useState(''); // Track current phase of streaming
    const [currentRequestId, setCurrentRequestId] = useState(null); // Track current request ID for correlation

    // Listen for model loading progress and streaming chunks
    // Use ref to access current state without re-registering listener
    const streamingMessageIdRef = useRef(streamingMessageId);
    const currentRequestIdRef = useRef(currentRequestId);

    // Update refs when state changes
    useEffect(() => {
        streamingMessageIdRef.current = streamingMessageId;
    }, [streamingMessageId]);

    useEffect(() => {
        currentRequestIdRef.current = currentRequestId;
    }, [currentRequestId]);

    // Single listener registration without dependencies
    useEffect(() => {
        const handleMessage = (message) => {
            if (message.type === 'RAG_MODEL_PROGRESS') {
                setModelLoading(true);
                // You could show detailed progress here if needed
            }

            // Handle streaming chunks (for both test generation and chat)
            if (message.action === 'TEST_CHUNK' && message.data) {
                const { chunk, fullContent, progress, isLastChunk } = message.data;
                const messageRequestId = message.requestId;

                // Only process chunks for current request
                if (messageRequestId && currentRequestIdRef.current && messageRequestId !== currentRequestIdRef.current) {
                    console.debug(`Ignoring chunk for different request: ${messageRequestId} !== ${currentRequestIdRef.current}`);
                    return;
                }

                // Check if this is the last chunk - finalize the message
                if (isLastChunk) {
                    console.log('âœ… Received last chunk, finalizing message');
                    setStreamingPhase('');
                    setCurrentRequestId(null);

                    // Mark message as complete
                    setMessages(prev => {
                        const existingIndex = prev.findIndex(m => m.id === streamingMessageIdRef.current);
                        if (existingIndex >= 0) {
                            const updated = [...prev];
                            updated[existingIndex] = {
                                ...updated[existingIndex],
                                isStreaming: false
                            };
                            setStreamingMessageId(null);
                            return updated;
                        }
                        return prev;
                    });

                    return; // Exit early, no need to process further
                }

                // Update streaming phase based on progress
                if (!streamingMessageIdRef.current) {
                    setStreamingPhase('ðŸ¤– AI analyzing code structure...');
                } else if (fullContent.length < 100) {
                    setStreamingPhase('ðŸ§  AI understanding context...');
                } else if (fullContent.length < 500) {
                    setStreamingPhase('âœ¨ AI generating response...');
                } else {
                    setStreamingPhase('ðŸ“ AI writing tests...');
                }

                setMessages(prev => {
                    // Find or create streaming message
                    const existingIndex = prev.findIndex(m => m.id === streamingMessageIdRef.current);

                    if (existingIndex >= 0) {
                        // Update existing streaming message
                        const updated = [...prev];
                        const currentMsg = updated[existingIndex];

                        // If message type is 'code', update code property
                        // If message type is 'text', update content property
                        if (currentMsg.type === 'code') {
                            updated[existingIndex] = {
                                ...currentMsg,
                                code: fullContent,
                                isStreaming: true,
                                progress
                            };
                        } else {
                            updated[existingIndex] = {
                                ...currentMsg,
                                content: fullContent,
                                isStreaming: true,
                                progress
                            };
                        }
                        return updated;
                    } else {
                        // Create new streaming message
                        // Detect if content looks like code (has backticks, function keywords, etc.)
                        const looksLikeCode = fullContent.includes('```') ||
                            fullContent.includes('function ') ||
                            fullContent.includes('describe(') ||
                            fullContent.includes('it(') ||
                            fullContent.includes('test(') ||
                            fullContent.includes('expect(');

                        const newId = Date.now();
                        setStreamingMessageId(newId);

                        if (looksLikeCode) {
                            return [...prev, {
                                id: newId,
                                role: 'assistant',
                                content: 'Generating tests...',
                                code: fullContent,
                                type: 'code',
                                isStreaming: true,
                                progress
                            }];
                        } else {
                            return [...prev, {
                                id: newId,
                                role: 'assistant',
                                content: fullContent,
                                type: 'text',
                                isStreaming: true,
                                progress
                            }];
                        }
                    }
                });
            }

            // Handle heartbeat messages (keep connection alive)
            if (message.action === 'HEARTBEAT') {
                console.log('ðŸ’“ Received heartbeat from background');
            }
        };

        chrome.runtime.onMessage.addListener(handleMessage);
        return () => chrome.runtime.onMessage.removeListener(handleMessage);
    }, []); // Empty dependency array - register listener only once

    // Initialize conversation history
    useEffect(() => {
        const initHistory = async () => {
            await conversationHistory.initialize();

            // Set code context from current tab if available
            try {
                const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });
                if (tab && tab.url) {
                    const url = new URL(tab.url);
                    if (url.hostname.includes('github.com') || url.hostname.includes('gitlab.com')) {
                        const pathParts = url.pathname.split('/');
                        await conversationHistory.setCodeContext({
                            filePath: pathParts.slice(3).join('/'),
                            language: 'auto',
                            repository: `${pathParts[1]}/${pathParts[2]}`
                        });
                    }
                }
            } catch (error) {
                console.error('Failed to set code context:', error);
            }
        };

        initHistory();
    }, []);

    // Track messages in conversation history
    useEffect(() => {
        // Save each new message to conversation history (skip initial welcome message)
        if (messages.length > 1) {
            const lastMessage = messages[messages.length - 1];
            if (lastMessage && !lastMessage.isStreaming) {
                conversationHistory.addMessage(lastMessage);
            }
        }
    }, [messages]);

    // Reset autoGenerated flag when autoGenerateType changes
    useEffect(() => {
        if (autoGenerateType) {
            setAutoGenerated(false);
        }
    }, [autoGenerateType]);

    // Auto-generate tests when autoGenerateType is provided
    useEffect(() => {
        if (autoGenerateType && !autoGenerated) {
            setAutoGenerated(true);

            // Trigger test generation automatically
            const generateAuto = async () => {
                const testTypePrompt = autoGenerateType === 'unit'
                    ? 'Generate comprehensive unit tests for this file'
                    : 'Generate comprehensive integration tests for this file';

                // Clear previous messages when starting new generation
                setMessages([{
                    id: 1,
                    role: 'assistant',
                    content: "Hi! I'm RepoSpector Copilot. I can help you with:\n\n**Test Generation:**\n\nâ€¢ generate unit tests\n\nâ€¢ create integration tests\n\nâ€¢ add pytest tests\n\n**Code Analysis:**\n\nâ€¢ explain this code\n\nâ€¢ find issues in this code\n\nâ€¢ suggest improvements\n\nâ€¢ how does this function work?\n\nâ€¢ what are potential bugs?\n\nWhat can I help you with?",
                    type: 'text'
                }]);

                // Add user message to show what was requested
                const userMessage = {
                    id: Date.now(),
                    role: 'user',
                    content: testTypePrompt,
                    type: 'text'
                };
                setMessages(prev => [...prev, userMessage]);

                // Show initial streaming phase
                setStreamingPhase('ðŸ” Extracting code for AI analysis...');

                try {
                    const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });

                    const response = await sendMessage('GENERATE_TESTS', {
                        tabId: tab?.id,
                        options: {
                            testType: autoGenerateType,
                            contextLevel: 'smart',
                            userPrompt: testTypePrompt
                        }
                    });

                    // Set current request ID for chunk correlation
                    if (response.requestId) {
                        setCurrentRequestId(response.requestId);
                    }

                    if (response.success) {
                        // Always clear streaming phase on successful response
                        setStreamingPhase('');

                        // Only create final message if streaming didn't already handle it
                        const testTypeName = autoGenerateType === 'unit' ? 'unit' : 'integration';

                        if (!streamingMessageId && response.testCases && response.testCases.trim()) {
                            // No streaming message exists, create new one
                            const aiMessage = {
                                id: Date.now() + 1,
                                role: 'assistant',
                                content: `I've generated ${testTypeName} tests using ${response.metadata?.framework || 'default'} for your ${response.metadata?.language || 'code'}:`,
                                type: 'code',
                                code: response.testCases,
                                metadata: response.metadata,
                                testType: testTypeName
                            };
                            setMessages(prev => [...prev, aiMessage]);
                        }
                        // If streamingMessageId exists, the streaming chunks already handled the message
                        if (streamingMessageId) {
                            setStreamingMessageId(null);
                        }
                    } else {
                        // Clear streaming phase on error too
                        setStreamingPhase('');
                        throw new Error(response.error || 'Failed to generate tests');
                    }
                } catch (err) {
                    // Clear streaming phase on error
                    setStreamingPhase('');
                    setStreamingMessageId(null);

                    const errorMessage = {
                        id: Date.now() + 1,
                        role: 'assistant',
                        content: `Error: ${err.message}. Please try again.`,
                        type: 'error'
                    };
                    setMessages(prev => [...prev, errorMessage]);
                }
            };

            generateAuto();
        }
    }, [autoGenerateType, autoGenerated, sendMessage]);

    const scrollToBottom = () => {
        messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
    };

    useEffect(() => {
        scrollToBottom();
    }, [messages]);

    const handleIndexRepo = async () => {
        let apiKey = null;

        // Only prompt for API key if using OpenAI
        if (embeddingProvider === 'openai') {
            apiKey = prompt("Please enter your OpenAI API Key for indexing:");
            if (!apiKey) return;
        }

        setIsIndexing(true);
        setModelLoading(embeddingProvider === 'transformers');

        const providerName = embeddingProvider === 'transformers' ? 'Free (Transformers.js)' : 'OpenAI';
        setMessages(prev => [...prev, {
            id: Date.now(),
            role: 'assistant',
            content: `Starting repository indexing with ${providerName}... ${embeddingProvider === 'transformers' ? 'Loading model (~25MB)...' : 'This may take a moment.'}`,
            type: 'text'
        }]);

        try {
            await initRAG({ provider: embeddingProvider, apiKey });
            setModelLoading(false);

            // Simulate getting files (in real app, we'd fetch from GitHub API)
            const mockFiles = [
                { path: 'src/utils/math.js', content: 'export const add = (a, b) => a + b;' },
                { path: 'src/components/Button.jsx', content: 'export const Button = () => <button>Click</button>;' }
            ];

            await indexRepo('owner/repo', mockFiles);

            setMessages(prev => [...prev, {
                id: Date.now(),
                role: 'assistant',
                content: `Repository indexed successfully with ${providerName}! I can now use Deep Context for your queries.`,
                type: 'text'
            }]);
        } catch (err) {
            setModelLoading(false);
            setMessages(prev => [...prev, {
                id: Date.now(),
                role: 'assistant',
                content: `Indexing failed: ${err.message}`,
                type: 'error'
            }]);
        } finally {
            setIsIndexing(false);
        }
    };

    const handleSubmit = async (e) => {
        e.preventDefault();
        if (!input.trim()) return;

        const userMessage = { id: Date.now(), role: 'user', content: input, type: 'text' };
        setMessages(prev => [...prev, userMessage]);
        // Save user message to history
        conversationHistory.addMessage(userMessage).catch(console.error);

        const userPrompt = input.toLowerCase();
        setInput('');

        // Show initial streaming phase
        setStreamingPhase('ðŸ” Preparing AI request...');

        try {
            // Detect if this is a test generation request (look for action verbs + test keywords)
            const lowerPrompt = userPrompt.toLowerCase();
            const isTestGeneration = (
                (lowerPrompt.includes('generate') || lowerPrompt.includes('create') || lowerPrompt.includes('write') || lowerPrompt.includes('add') || lowerPrompt.includes('make')) &&
                (lowerPrompt.includes('test') || lowerPrompt.includes('spec'))
            ) || lowerPrompt === 'test' || lowerPrompt === 'tests';

            const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });

            // Route to appropriate handler
            if (isTestGeneration) {
                // Update phase for test generation
                setStreamingPhase('ðŸ¤– Sending code to AI for test generation...');
                // Test generation flow
                let testType = 'unit'; // Default
                let contextLevel = 'smart';

                if (userPrompt.includes('integration')) {
                    testType = 'integration';
                } else if (userPrompt.includes('e2e') || userPrompt.includes('end-to-end') || userPrompt.includes('end to end')) {
                    testType = 'e2e';
                } else if (userPrompt.includes('api')) {
                    testType = 'api';
                } else if (userPrompt.includes('performance')) {
                    testType = 'performance';
                } else if (userPrompt.includes('security')) {
                    testType = 'security';
                }

                // Parse context level from prompt
                if (userPrompt.includes('comprehensive') || userPrompt.includes('detailed') || userPrompt.includes('full context')) {
                    contextLevel = 'full';
                } else if (userPrompt.includes('minimal') || userPrompt.includes('simple')) {
                    contextLevel = 'minimal';
                }

                const response = await sendMessage('GENERATE_TESTS', {
                    tabId: tab?.id,
                    options: {
                        testType,
                        contextLevel,
                        userPrompt: input
                    }
                });

                // Set current request ID for chunk correlation
                if (response.requestId) {
                    setCurrentRequestId(response.requestId);
                }

                if (response.success) {
                    // Always clear streaming phase on successful response
                    setStreamingPhase('');

                    // Only create final message if streaming didn't already handle it
                    // If streamingMessageId exists, streaming already created the message
                    if (!streamingMessageId && response.testCases && response.testCases.trim()) {
                        // No streaming message exists, create new one
                        const testTypeName = testType === 'unit' ? 'unit' :
                            testType === 'integration' ? 'integration' :
                                testType === 'e2e' ? 'end-to-end' :
                                    testType === 'api' ? 'API' :
                                        testType;

                        const aiMessage = {
                            id: Date.now() + 1,
                            role: 'assistant',
                            content: `I've generated ${testTypeName} tests using ${response.metadata?.framework || 'unit'} for your ${response.metadata?.language || 'code'}:`,
                            type: 'code',
                            code: response.testCases,
                            metadata: response.metadata,
                            testType: testTypeName
                        };
                        setMessages(prev => [...prev, aiMessage]);
                        // Save AI response to history
                        conversationHistory.addMessage(aiMessage).catch(console.error);
                    }
                    // If streamingMessageId exists, the streaming chunks already handled the message
                    // Just clear the streaming state
                    if (streamingMessageId) {
                        setStreamingMessageId(null);
                    }
                } else {
                    // Clear streaming phase on error too
                    setStreamingPhase('');
                    throw new Error(response.error || 'Failed to generate tests');
                }
            } else {
                // General code chat flow (Ask Copilot)
                setStreamingPhase('ðŸ’¬ Asking AI about your code...');

                // Get formatted conversation history
                const history = conversationHistory.getFormattedHistory(true);
                console.log('ðŸ“š Sending conversation history:', history.length, 'messages');

                const response = await sendMessage('CHAT_WITH_CODE', {
                    tabId: tab?.id,
                    question: input,
                    conversationHistory: history  // ADD conversation history
                });

                // Set current request ID for chunk correlation
                if (response.requestId) {
                    setCurrentRequestId(response.requestId);
                }

                if (response.success) {
                    // Always clear streaming phase on successful response
                    setStreamingPhase('');

                    // Only create final message if streaming didn't already handle it
                    // If streamingMessageId exists, streaming already created the message
                    if (!streamingMessageId && response.response && response.response.trim()) {
                        // No streaming message exists, create new one
                        const aiMessage = {
                            id: Date.now() + 1,
                            role: 'assistant',
                            content: response.response,
                            type: 'text',
                            metadata: response.metadata
                        };
                        setMessages(prev => [...prev, aiMessage]);
                        // Save AI response to history
                        conversationHistory.addMessage(aiMessage).catch(console.error);
                    }
                    // If streamingMessageId exists, the streaming chunks already handled the message
                    // Just clear the streaming state
                    if (streamingMessageId) {
                        setStreamingMessageId(null);
                    }
                } else {
                    // Clear streaming phase on error too
                    setStreamingPhase('');
                    throw new Error(response.error || 'Failed to get response');
                }
            }
        } catch (err) {
            // Clear streaming phase on error
            setStreamingPhase('');
            setStreamingMessageId(null);
            setCurrentRequestId(null);

            // Provide helpful error messages based on error type
            let errorContent = `Error: ${err.message}`;
            let suggestions = [];

            if (err.message.includes('timeout')) {
                errorContent = 'â±ï¸ Request timed out';
                suggestions.push('The operation took too long. Try with a smaller code file or simpler request.');
            } else if (err.message.includes('API key')) {
                errorContent = 'ðŸ”‘ API Key Error';
                suggestions.push('Please check your API key in settings.');
                suggestions.push('Make sure the key is valid and has sufficient credits.');
            } else if (err.message.includes('No code found') || err.message.includes('extract')) {
                errorContent = 'ðŸ“„ Could not extract code from this page';
                suggestions.push('Make sure you\'re on a GitHub or GitLab code file.');
                suggestions.push('Try refreshing the page and reopening the extension.');
            } else if (err.message.includes('rate limit') || err.message.includes('429')) {
                errorContent = 'ðŸš¦ Rate limit exceeded';
                suggestions.push('Please wait a moment before trying again.');
                suggestions.push('Consider using a different API key or upgrading your plan.');
            } else if (err.message.includes('buffer limit') || err.message.includes('too large')) {
                errorContent = 'ðŸ’¾ Response too large';
                suggestions.push('The code file is too large to process.');
                suggestions.push('Try selecting a smaller section of code.');
            }

            const fullErrorMessage = suggestions.length > 0
                ? `${errorContent}\n\n**Suggestions:**\n${suggestions.map(s => `â€¢ ${s}`).join('\n')}`
                : errorContent + '\n\nPlease try again or contact support if the issue persists.';

            const errorMessage = {
                id: Date.now() + 1,
                role: 'assistant',
                content: fullErrorMessage,
                type: 'error'
            };
            setMessages(prev => [...prev, errorMessage]);
        }
    };

    return (
        <div className="flex flex-col h-full w-full">
            <div className="flex-1 overflow-y-auto space-y-4 p-4 pb-20 min-h-0">
                {messages.map((msg) => (
                    <div
                        key={msg.id}
                        className={cn(
                            "flex gap-3",
                            msg.type === 'code' ? "max-w-full" : "max-w-[90%]",
                            msg.role === 'user' ? "ml-auto flex-row-reverse" : ""
                        )}
                    >
                        <div className={cn(
                            "w-8 h-8 rounded-full flex items-center justify-center shrink-0",
                            msg.role === 'assistant' ? "bg-primary/20 text-primary" : "bg-surfaceHighlight text-text",
                            msg.type === 'error' && "bg-error/20 text-error",
                            msg.type === 'info' && "bg-blue-500/20 text-blue-400"
                        )}>
                            {msg.role === 'assistant' && <Bot className="w-5 h-5" />}
                            {msg.role === 'user' && <User className="w-5 h-5" />}
                            {msg.type === 'error' && <AlertCircle className="w-5 h-5" />}
                            {msg.type === 'info' && <Sparkles className="w-5 h-5" />}
                        </div>

                        <div className={cn("space-y-2", msg.type === 'code' ? "flex-1 min-w-0" : "w-full")}>
                            {msg.content && (
                                <div className={cn(
                                    "p-3 rounded-2xl text-sm whitespace-pre-line",
                                    msg.role === 'assistant'
                                        ? "bg-surfaceHighlight/50 rounded-tl-none"
                                        : "bg-primary text-white rounded-tr-none",
                                    msg.type === 'error' && "bg-error/10 text-error border border-error/20",
                                    msg.type === 'info' && "bg-blue-500/10 text-blue-300 border border-blue-500/20"
                                )}>
                                    {formatMessageContent(msg.content)}
                                </div>
                            )}

                            {msg.type === 'code' && (
                                <div className="animate-fade-in space-y-3">
                                    <CodePreview
                                        code={msg.code}
                                        language={msg.testType ? `${msg.testType} tests` : 'javascript'}
                                    />

                                    {/* Quick action buttons for test generation */}
                                    {!msg.isStreaming && (
                                        <div className="flex gap-2 flex-wrap">
                                            <Button
                                                size="sm"
                                                variant="outline"
                                                onClick={async () => {
                                                    const prompt = 'generate more test cases for edge cases and error handling';
                                                    const userMessage = { id: Date.now(), role: 'user', content: prompt, type: 'text' };
                                                    setMessages(prev => [...prev, userMessage]);
                                                    setStreamingPhase('ðŸ¤– Sending code to AI for test generation...');

                                                    try {
                                                        const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });
                                                        const response = await sendMessage('GENERATE_TESTS', {
                                                            tabId: tab?.id,
                                                            options: {
                                                                testType: 'unit',
                                                                contextLevel: 'smart',
                                                                userPrompt: prompt
                                                            }
                                                        });

                                                        if (response.requestId) {
                                                            setCurrentRequestId(response.requestId);
                                                        }
                                                    } catch (err) {
                                                        setStreamingPhase('');
                                                        setMessages(prev => [...prev, {
                                                            id: Date.now(),
                                                            role: 'assistant',
                                                            content: `Error: ${err.message}`,
                                                            type: 'error'
                                                        }]);
                                                    }
                                                }}
                                                className="text-xs"
                                                disabled={isLoading || streamingPhase}
                                            >
                                                <User className="w-3 h-3 mr-1" />
                                                Generate more test cases
                                            </Button>
                                            <Button
                                                size="sm"
                                                variant="outline"
                                                onClick={async () => {
                                                    const prompt = 'add integration tests for this code';
                                                    const userMessage = { id: Date.now(), role: 'user', content: prompt, type: 'text' };
                                                    setMessages(prev => [...prev, userMessage]);
                                                    setStreamingPhase('ðŸ¤– Sending code to AI for test generation...');

                                                    try {
                                                        const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });
                                                        const response = await sendMessage('GENERATE_TESTS', {
                                                            tabId: tab?.id,
                                                            options: {
                                                                testType: 'integration',
                                                                contextLevel: 'smart',
                                                                userPrompt: prompt
                                                            }
                                                        });

                                                        if (response.requestId) {
                                                            setCurrentRequestId(response.requestId);
                                                        }
                                                    } catch (err) {
                                                        setStreamingPhase('');
                                                        setMessages(prev => [...prev, {
                                                            id: Date.now(),
                                                            role: 'assistant',
                                                            content: `Error: ${err.message}`,
                                                            type: 'error'
                                                        }]);
                                                    }
                                                }}
                                                className="text-xs"
                                                disabled={isLoading || streamingPhase}
                                            >
                                                <User className="w-3 h-3 mr-1" />
                                                Add integration tests
                                            </Button>
                                        </div>
                                    )}
                                </div>
                            )}

                            {/* Show AI badge for assistant messages (except first welcome message) */}
                            {msg.role === 'assistant' && msg.id !== 1 && !msg.isStreaming && (
                                <div className="flex items-center gap-1 text-xs text-textMuted/60 mt-1">
                                    <Sparkles className="w-3 h-3" />
                                    <span>Generated by AI</span>
                                </div>
                            )}
                        </div>
                    </div>
                ))}

                {/* Welcome/Empty State - Removed RAG indexing buttons for cleaner interface */}

                {(isLoading || streamingPhase) && (
                    <div className="flex gap-3">
                        <div className="w-8 h-8 rounded-full bg-primary/20 text-primary flex items-center justify-center">
                            <Sparkles className="w-4 h-4 animate-pulse" />
                        </div>
                        <div className="bg-surfaceHighlight/50 p-3 rounded-2xl rounded-tl-none">
                            {streamingPhase ? (
                                <div className="flex items-center gap-2">
                                    <div className="flex gap-1">
                                        <div className="w-2 h-2 bg-primary/70 rounded-full animate-bounce" style={{ animationDelay: '0ms' }} />
                                        <div className="w-2 h-2 bg-primary/70 rounded-full animate-bounce" style={{ animationDelay: '150ms' }} />
                                        <div className="w-2 h-2 bg-primary/70 rounded-full animate-bounce" style={{ animationDelay: '300ms' }} />
                                    </div>
                                    <span className="text-sm text-text/80">{streamingPhase}</span>
                                </div>
                            ) : (
                                <div className="flex items-center gap-1">
                                    <div className="w-2 h-2 bg-textMuted/50 rounded-full animate-bounce" style={{ animationDelay: '0ms' }} />
                                    <div className="w-2 h-2 bg-textMuted/50 rounded-full animate-bounce" style={{ animationDelay: '150ms' }} />
                                    <div className="w-2 h-2 bg-textMuted/50 rounded-full animate-bounce" style={{ animationDelay: '300ms' }} />
                                </div>
                            )}
                        </div>
                    </div>
                )}
                <div ref={messagesEndRef} />
            </div>

            <div className="absolute bottom-0 left-0 right-0 p-4 bg-background/80 backdrop-blur-md border-t border-white/5">
                <form onSubmit={handleSubmit} className="relative">
                    <input
                        type="text"
                        value={input}
                        onChange={(e) => setInput(e.target.value)}
                        placeholder="Type your request (e.g., 'generate unit tests')..."
                        className="w-full h-12 pl-4 pr-12 bg-surfaceHighlight/50 border border-white/10 rounded-xl focus:outline-none focus:border-primary focus:ring-1 focus:ring-primary transition-all placeholder:text-textMuted"
                        disabled={isLoading || isIndexing}
                        autoFocus
                    />
                    <Button
                        type="submit"
                        size="icon"
                        disabled={!input.trim() || isLoading || isIndexing}
                        className="absolute right-2 top-1/2 -translate-y-1/2 h-8 w-8"
                    >
                        <Send className="w-4 h-4" />
                    </Button>
                </form>
            </div>
        </div>
    );
}
