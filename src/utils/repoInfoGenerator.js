/**
 * RepoInfo.md Generator for RepoSpector
 *
 * Generates a comprehensive markdown document from indexed repo data.
 * No LLM needed — everything is extracted from file contents via pattern matching.
 */
export function generateRepoInfo(fileContents, importGraph, repoId) {
    if (!fileContents || fileContents.size === 0) return null;

    const filePaths = [...fileContents.keys()].sort();

    const sections = [
        generateHeader(repoId),
        generateOverview(filePaths, fileContents, importGraph),
        generateTechStack(fileContents, filePaths),
        generateArchitectureOverview(filePaths, importGraph, fileContents),
        generateDirectoryStructure(filePaths),
        generateKeyClassesAndFunctions(fileContents, filePaths),
        generateAPIReference(fileContents),
        generateEventSystem(fileContents, filePaths),
        generateDBSchemas(fileContents, filePaths),
        generateExternalServices(fileContents, filePaths),
        generateDependencies(fileContents, filePaths),
        generateFileDependencyGraph(importGraph, filePaths),
        generateConstantsAndEnums(fileContents, filePaths),
        generateErrorHandling(fileContents, filePaths),
        generateCronJobs(fileContents, filePaths),
        generateTestStructure(fileContents, filePaths),
        generateConfiguration(fileContents, filePaths),
        generateFileIndex(filePaths, importGraph, fileContents),
    ];

    return sections.filter(Boolean).join('\n\n---\n\n');
}

// ── Helpers ──────────────────────────────────────────────────────────────────

const EXT_LANG = {
    '.js': 'JavaScript', '.jsx': 'JavaScript (JSX)', '.ts': 'TypeScript', '.tsx': 'TypeScript (TSX)',
    '.py': 'Python', '.java': 'Java', '.go': 'Go', '.rb': 'Ruby', '.rs': 'Rust',
    '.c': 'C', '.cpp': 'C++', '.cs': 'C#', '.php': 'PHP', '.swift': 'Swift',
    '.kt': 'Kotlin', '.scala': 'Scala', '.vue': 'Vue', '.svelte': 'Svelte',
    '.html': 'HTML', '.css': 'CSS', '.scss': 'SCSS', '.less': 'Less',
    '.json': 'JSON', '.yaml': 'YAML', '.yml': 'YAML', '.toml': 'TOML',
    '.md': 'Markdown', '.sql': 'SQL', '.sh': 'Shell', '.bash': 'Shell',
    '.r': 'R', '.lua': 'Lua', '.dart': 'Dart', '.ex': 'Elixir', '.exs': 'Elixir',
    '.prisma': 'Prisma',
};

function langFromPath(fp) {
    const ext = '.' + fp.split('.').pop().toLowerCase();
    return EXT_LANG[ext] || null;
}

function extractFirstComment(content) {
    if (!content) return null;
    const first = content.slice(0, 2000);
    const block = first.match(/\/\*\*?\s*\n?\s*\*?\s*(.+?)(?:\n|\*\/)/);
    if (block) return block[1].replace(/^\s*\*\s*/, '').trim().slice(0, 150);
    const pyDoc = first.match(/(?:^|\n)\s*(?:"""|''')([\s\S]*?)(?:"""|''')/);
    if (pyDoc) return pyDoc[1].trim().split('\n')[0].slice(0, 150);
    const lines = first.split('\n');
    for (const line of lines.slice(0, 10)) {
        const t = line.trim();
        if (t.startsWith('#!')) continue;
        if (t.startsWith('//') || t.startsWith('#')) {
            const text = t.replace(/^\/\/\s*/, '').replace(/^#\s*/, '').trim();
            if (text.length > 5) return text.slice(0, 150);
        }
        if (t && !t.startsWith('import') && !t.startsWith('from') && !t.startsWith('use') && !t.startsWith('package')) break;
    }
    return null;
}

function countLines(content) {
    return content ? content.split('\n').length : 0;
}

function safeMd(s) {
    return (s || '').replace(/\|/g, '\\|').replace(/\n/g, ' ');
}

// ── Section Generators ───────────────────────────────────────────────────────

function generateHeader(repoId) {
    const date = new Date().toISOString().split('T')[0];
    return `# RepoInfo: ${repoId}

> Generated by RepoSpector on ${date}
> This document provides a comprehensive overview of the repository for use as LLM context.
> All information is extracted from indexed source code — no AI was used to generate this document.`;
}

function generateOverview(filePaths, fileContents, importGraph) {
    const totalFiles = filePaths.length;
    let totalLines = 0;
    const langCount = {};

    for (const fp of filePaths) {
        const lang = langFromPath(fp);
        if (lang) langCount[lang] = (langCount[lang] || 0) + 1;
        totalLines += countLines(fileContents.get(fp));
    }

    const sorted = Object.entries(langCount).sort((a, b) => b[1] - a[1]);
    const langTable = sorted.map(([lang, count]) => `| ${lang} | ${count} | ${((count / totalFiles) * 100).toFixed(1)}% |`).join('\n');

    // Count classes and functions across all files
    let totalClasses = 0, totalFunctions = 0;
    for (const [, content] of fileContents) {
        if (!content) continue;
        totalClasses += (content.match(/\bclass\s+\w+/g) || []).length;
        totalFunctions += (content.match(/\bdef\s+\w+|function\s+\w+|(?:const|let|var)\s+\w+\s*=\s*(?:async\s+)?\(/g) || []).length;
    }

    return `## Repository Overview

| Metric | Value |
|--------|-------|
| Total Files | ${totalFiles} |
| Estimated Lines of Code | ~${totalLines.toLocaleString()} |
| Languages Detected | ${sorted.length} |
| Classes | ~${totalClasses} |
| Functions / Methods | ~${totalFunctions} |

### Language Distribution

| Language | Files | Percentage |
|----------|-------|------------|
${langTable}`;
}

function generateTechStack(fileContents, filePaths) {
    const stack = { languages: new Set(), frameworks: new Set(), databases: new Set(), messaging: new Set(), buildTools: new Set(), packageManagers: new Set(), testing: new Set(), cloud: new Set() };

    // --- Detect from manifest files ---
    const pkgPath = filePaths.find(fp => fp.endsWith('package.json') && !fp.includes('node_modules'));
    if (pkgPath) {
        try {
            const pkg = JSON.parse(fileContents.get(pkgPath));
            const allDeps = { ...pkg.dependencies, ...pkg.devDependencies };
            stack.packageManagers.add('npm/yarn');
            stack.languages.add('JavaScript/TypeScript');
            if (pkg.engines?.node) stack.languages.add(`Node.js ${pkg.engines.node}`);
            const maps = {
                frameworks: { 'react': 'React', 'next': 'Next.js', 'vue': 'Vue.js', 'nuxt': 'Nuxt.js', 'angular': 'Angular', '@angular/core': 'Angular', 'svelte': 'Svelte', 'express': 'Express.js', 'fastify': 'Fastify', 'koa': 'Koa', '@nestjs/core': 'NestJS', 'hapi': 'Hapi', 'gatsby': 'Gatsby', 'remix': 'Remix', 'electron': 'Electron', 'react-native': 'React Native' },
                databases: { 'pg': 'PostgreSQL', 'mysql': 'MySQL', 'mysql2': 'MySQL', 'mongodb': 'MongoDB', 'mongoose': 'MongoDB (Mongoose)', 'redis': 'Redis', 'ioredis': 'Redis', 'sqlite3': 'SQLite', 'sequelize': 'Sequelize ORM', 'typeorm': 'TypeORM', '@prisma/client': 'Prisma', 'knex': 'Knex.js', 'drizzle-orm': 'Drizzle ORM' },
                messaging: { 'kafkajs': 'Kafka', 'amqplib': 'RabbitMQ', 'bull': 'Bull (Redis Queue)', 'bullmq': 'BullMQ', '@google-cloud/pubsub': 'Google Pub/Sub', 'aws-sdk': 'AWS SDK' },
                buildTools: { 'webpack': 'Webpack', 'vite': 'Vite', 'esbuild': 'esbuild', 'rollup': 'Rollup', 'typescript': 'TypeScript', '@babel/core': 'Babel', 'tailwindcss': 'Tailwind CSS' },
                testing: { 'jest': 'Jest', 'mocha': 'Mocha', 'vitest': 'Vitest', 'cypress': 'Cypress', '@playwright/test': 'Playwright', 'supertest': 'Supertest' },
            };
            for (const [cat, map] of Object.entries(maps)) {
                for (const [dep, name] of Object.entries(map)) {
                    if (allDeps[dep]) stack[cat].add(`${name} (${allDeps[dep]})`);
                }
            }
        } catch (e) { /* ignore */ }
    }

    const reqPath = filePaths.find(fp => /requirements\.txt$/.test(fp));
    const pipfilePath = filePaths.find(fp => fp.endsWith('Pipfile'));
    const pyprojectPath = filePaths.find(fp => fp.endsWith('pyproject.toml'));
    if (reqPath || pipfilePath || pyprojectPath) {
        stack.languages.add('Python');
        if (reqPath) stack.packageManagers.add('pip');
        if (pipfilePath) stack.packageManagers.add('pipenv');
        if (pyprojectPath) stack.packageManagers.add('poetry');
        const pyContent = fileContents.get(reqPath) || fileContents.get(pipfilePath) || '';
        const pyMap = { 'django': 'Django', 'flask': 'Flask', 'fastapi': 'FastAPI', 'celery': 'Celery', 'sqlalchemy': 'SQLAlchemy', 'alembic': 'Alembic', 'pytest': 'Pytest', 'numpy': 'NumPy', 'pandas': 'Pandas', 'tensorflow': 'TensorFlow', 'torch': 'PyTorch' };
        for (const [dep, name] of Object.entries(pyMap)) {
            if (pyContent.toLowerCase().includes(dep)) stack.frameworks.add(name);
        }
    }

    const goModPath = filePaths.find(fp => fp.endsWith('go.mod'));
    if (goModPath) { stack.languages.add('Go'); stack.packageManagers.add('Go Modules'); }
    const cargoPath = filePaths.find(fp => fp.endsWith('Cargo.toml'));
    if (cargoPath) { stack.languages.add('Rust'); stack.packageManagers.add('Cargo'); }
    const gemfilePath = filePaths.find(fp => fp.endsWith('Gemfile') && !fp.endsWith('.lock'));
    if (gemfilePath) { stack.languages.add('Ruby'); stack.packageManagers.add('Bundler'); }
    const pomPath = filePaths.find(fp => fp.endsWith('pom.xml'));
    const gradlePath = filePaths.find(fp => fp.endsWith('build.gradle') || fp.endsWith('build.gradle.kts'));
    if (pomPath || gradlePath) { stack.languages.add('Java/Kotlin'); stack.packageManagers.add(pomPath ? 'Maven' : 'Gradle'); }

    if (filePaths.some(fp => /Dockerfile$/i.test(fp.split('/').pop()))) stack.buildTools.add('Docker');
    if (filePaths.some(fp => /docker-compose/i.test(fp))) stack.buildTools.add('Docker Compose');

    // --- Import-based detection (crucial when no manifest files are indexed) ---
    const importDetectors = {
        frameworks: {
            'flask': 'Flask', 'django': 'Django', 'fastapi': 'FastAPI', 'tornado': 'Tornado',
            'sqlalchemy': 'SQLAlchemy', 'peewee': 'Peewee ORM', 'mongoengine': 'MongoEngine',
            'celery': 'Celery', 'dramatiq': 'Dramatiq', 'pydantic': 'Pydantic',
            'marshmallow': 'Marshmallow', 'aiohttp': 'aiohttp', 'sanic': 'Sanic',
            'spring': 'Spring', 'gin': 'Gin', 'echo': 'Echo',
        },
        databases: {
            'pymongo': 'MongoDB', 'psycopg2': 'PostgreSQL', 'mysql.connector': 'MySQL',
            'redis': 'Redis', 'sqlite3': 'SQLite', 'cassandra': 'Cassandra',
            'elasticsearch': 'Elasticsearch', 'boto3': 'AWS (DynamoDB/S3)',
            'mongoengine': 'MongoDB', 'peewee': 'SQL Database',
        },
        messaging: {
            'kafka': 'Apache Kafka', 'confluent_kafka': 'Kafka (Confluent)',
            'pika': 'RabbitMQ', 'celery': 'Celery', 'kombu': 'Kombu (AMQP)',
            'boto3.client.*sqs': 'AWS SQS', 'google.cloud.pubsub': 'Google Pub/Sub',
            'nats': 'NATS',
        },
        testing: {
            'pytest': 'Pytest', 'unittest': 'unittest', 'nose': 'Nose',
            'hypothesis': 'Hypothesis', 'mock': 'unittest.mock',
        },
        cloud: {
            'boto3': 'AWS SDK', 'google.cloud': 'Google Cloud',
            'azure': 'Azure SDK',
        }
    };

    for (const [, content] of fileContents) {
        if (!content) continue;
        const imports = content.match(/(?:from|import)\s+[\w.]+/g) || [];
        const allImportText = imports.join(' ').toLowerCase();

        for (const [cat, map] of Object.entries(importDetectors)) {
            for (const [keyword, name] of Object.entries(map)) {
                if (allImportText.includes(keyword.toLowerCase())) {
                    stack[cat].add(name);
                }
            }
        }
    }

    // Also detect language from file extensions if no manifest
    const pyFiles = filePaths.filter(fp => fp.endsWith('.py'));
    if (pyFiles.length > 0) stack.languages.add('Python');
    const jsFiles = filePaths.filter(fp => /\.(js|jsx|ts|tsx)$/.test(fp));
    if (jsFiles.length > 0) stack.languages.add('JavaScript/TypeScript');
    const goFiles = filePaths.filter(fp => fp.endsWith('.go'));
    if (goFiles.length > 0) stack.languages.add('Go');
    const javaFiles = filePaths.filter(fp => fp.endsWith('.java'));
    if (javaFiles.length > 0) stack.languages.add('Java');

    // Deduplicate
    for (const key of Object.keys(stack)) stack[key] = [...stack[key]];

    const hasAnything = Object.values(stack).some(arr => arr.length > 0);
    if (!hasAnything) return null;

    let md = '## Tech Stack\n\n';
    const cats = [
        ['Languages', stack.languages],
        ['Frameworks & Libraries', stack.frameworks],
        ['Databases & Storage', stack.databases],
        ['Messaging & Queues', stack.messaging],
        ['Cloud & Infrastructure', stack.cloud],
        ['Build Tools', stack.buildTools],
        ['Package Managers', stack.packageManagers],
        ['Testing', stack.testing],
    ];
    for (const [label, items] of cats) {
        if (items.length) md += `**${label}:** ${items.join(', ')}\n\n`;
    }

    return md.trim();
}

function generateArchitectureOverview(filePaths, importGraph, fileContents) {
    const layers = {
        'Frontend / UI': [], 'Backend / API': [], 'Services / Business Logic': [],
        'Models / Data': [], 'Events / Messaging': [], 'Utilities / Helpers': [],
        'Database / Migrations': [], 'Tests': [], 'Configuration': [], 'Documentation': [],
    };

    const layerPatterns = [
        { layer: 'Frontend / UI', patterns: [/^components?$/i, /^views?$/i, /^pages?$/i, /^layouts?$/i, /^popup$/i, /^ui$/i, /^frontend$/i, /^templates?$/i] },
        { layer: 'Backend / API', patterns: [/^routes?$/i, /^controllers?$/i, /^api$/i, /^handlers?$/i, /^endpoints?$/i, /^server$/i, /^backend$/i, /^middleware$/i] },
        { layer: 'Services / Business Logic', patterns: [/^services?$/i, /^providers?$/i, /^managers?$/i, /^workers?$/i] },
        { layer: 'Models / Data', patterns: [/^models?$/i, /^entities$/i, /^types?$/i, /^schemas?$/i] },
        { layer: 'Events / Messaging', patterns: [/^events?$/i, /^consumers?$/i, /^producers?$/i, /^callbacks?$/i, /^listeners?$/i, /^subscribers?$/i] },
        { layer: 'Database / Migrations', patterns: [/^dbs?$/i, /^database$/i, /^migrations?$/i, /^alembic$/i] },
        { layer: 'Utilities / Helpers', patterns: [/^utils?$/i, /^helpers?$/i, /^lib$/i, /^common$/i, /^shared$/i, /^tools?$/i] },
        { layer: 'Tests', patterns: [/^tests?$/i, /^specs?$/i, /^__tests__$/i, /^e2e$/i] },
        { layer: 'Configuration', patterns: [/^config$/i, /^\.github$/i, /^docker$/i, /^scripts?$/i, /^deploy$/i, /^ci$/i, /^inits?$/i] },
        { layer: 'Documentation', patterns: [/^docs?$/i, /^documentation$/i] },
    ];

    for (const fp of filePaths) {
        const parts = fp.toLowerCase().split('/');
        for (const { layer, patterns } of layerPatterns) {
            if (patterns.some(p => parts.some(part => p.test(part)))) {
                layers[layer].push(fp);
                break;
            }
        }
    }

    let md = '## Architecture Overview\n\n';

    // Narrative summary
    const layerSummaries = [];
    for (const [layer, files] of Object.entries(layers)) {
        if (files.length > 0) layerSummaries.push(`**${layer}** (${files.length} files)`);
    }
    md += `This repository is organized into ${layerSummaries.length} main layers: ${layerSummaries.join(', ')}.\n\n`;

    md += '### Module Layers\n\n';
    for (const [layer, files] of Object.entries(layers)) {
        if (files.length === 0) continue;
        const dirs = [...new Set(files.map(fp => fp.split('/').slice(0, 2).join('/')))].sort();
        md += `#### ${layer} (${files.length} files)\n\n`;
        for (const dir of dirs.slice(0, 10)) {
            const count = files.filter(fp => fp.startsWith(dir)).length;
            md += `- \`${dir}/\` — ${count} files\n`;
        }
        if (dirs.length > 10) md += `- ...and ${dirs.length - 10} more directories\n`;
        md += '\n';
    }

    // Entry points
    const fileSet = new Set(filePaths);
    const importedBy = new Map();
    if (importGraph) {
        for (const [fp, data] of importGraph) {
            if (!data?.imports) continue;
            for (const imp of data.imports) {
                for (const target of resolveImportTarget(imp.source, fp, fileSet)) {
                    if (!importedBy.has(target)) importedBy.set(target, []);
                    importedBy.get(target).push(fp);
                }
            }
        }
    }

    const entryPoints = filePaths.filter(fp => {
        const name = fp.split('/').pop().toLowerCase();
        const noImporters = !importedBy.has(fp) || importedBy.get(fp).length === 0;
        const isCode = /\.(js|ts|jsx|tsx|py|java|go|rb|rs)$/.test(fp);
        const isEntry = /^(index|main|app|server|start|entry|manage|wsgi|asgi|__init__)\./i.test(name);
        return isCode && (noImporters && isEntry);
    }).slice(0, 30);

    if (entryPoints.length) {
        md += '### Entry Points\n\n';
        for (const ep of entryPoints) {
            const comment = extractFirstComment(fileContents?.get(ep));
            md += `- \`${ep}\`${comment ? ` — ${comment}` : ''}\n`;
        }
    }

    return md.trim();
}

function generateDirectoryStructure(filePaths) {
    const MAX_DEPTH = 8;
    const COLLAPSE_THRESHOLD = 25;
    const tree = {};
    for (const fp of filePaths) {
        const parts = fp.split('/');
        let node = tree;
        for (let i = 0; i < parts.length; i++) {
            const part = parts[i];
            if (i === parts.length - 1) {
                if (!node.__files__) node.__files__ = [];
                node.__files__.push(part);
            } else {
                if (!node[part]) node[part] = {};
                node = node[part];
            }
        }
    }

    function countFilesInNode(node) {
        let c = (node.__files__ || []).length;
        for (const k of Object.keys(node)) { if (k !== '__files__') c += countFilesInNode(node[k]); }
        return c;
    }

    function renderTree(node, prefix, depth) {
        if (depth > MAX_DEPTH) return prefix + '...\n';
        let output = '';
        const dirs = Object.keys(node).filter(k => k !== '__files__').sort();
        const files = (node.__files__ || []).sort();
        const entries = [...dirs.map(d => ({ name: d, isDir: true })), ...files.map(f => ({ name: f, isDir: false }))];
        for (let i = 0; i < entries.length; i++) {
            const e = entries[i];
            const isLast = i === entries.length - 1;
            const conn = isLast ? '└── ' : '├── ';
            const childPfx = prefix + (isLast ? '    ' : '│   ');
            if (e.isDir) {
                const childNode = node[e.name];
                const total = countFilesInNode(childNode);
                if (total > COLLAPSE_THRESHOLD && depth >= 2) {
                    output += `${prefix}${conn}${e.name}/ (${total} files)\n`;
                } else {
                    output += `${prefix}${conn}${e.name}/\n`;
                    output += renderTree(childNode, childPfx, depth + 1);
                }
            } else {
                output += `${prefix}${conn}${e.name}\n`;
            }
        }
        return output;
    }

    return `## Directory Structure\n\n\`\`\`\n${renderTree(tree, '', 0)}\`\`\``;
}

function generateKeyClassesAndFunctions(fileContents, filePaths) {
    const fileClasses = [];

    for (const fp of filePaths) {
        const content = fileContents.get(fp);
        if (!content) continue;
        const lang = langFromPath(fp);
        if (!lang || /JSON|YAML|TOML|Markdown|CSS|HTML/.test(lang)) continue;

        const classes = [];
        const standaloneFunctions = [];

        // Python classes
        const pyClassRe = /^class\s+(\w+)\s*(?:\(([^)]*)\))?\s*:/gm;
        let cm;
        while ((cm = pyClassRe.exec(content)) !== null) {
            const className = cm[1];
            const bases = cm[2] ? cm[2].split(',').map(b => b.trim()) : [];
            // Find methods of this class
            const classStart = cm.index;
            const afterClass = content.slice(classStart);
            const methodRe = /^\s{4}(?:def|async\s+def)\s+(\w+)\s*\(/gm;
            const methods = [];
            let mm;
            while ((mm = methodRe.exec(afterClass)) !== null) {
                if (mm.index > 0 && afterClass.slice(0, mm.index).split('\n').pop().trim() === '') continue;
                methods.push(mm[1]);
                if (methods.length >= 30) break;
            }
            // Get docstring
            const docMatch = afterClass.match(/class\s+\w+[^:]*:\s*\n\s*(?:"""|''')([\s\S]*?)(?:"""|''')/);
            const doc = docMatch ? docMatch[1].trim().split('\n')[0].slice(0, 120) : null;
            classes.push({ name: className, bases, methods, doc });
        }

        // JS/TS classes
        const jsClassRe = /(?:export\s+)?class\s+(\w+)\s*(?:extends\s+(\w+))?\s*\{/g;
        while ((cm = jsClassRe.exec(content)) !== null) {
            const className = cm[1];
            const bases = cm[2] ? [cm[2]] : [];
            const classStart = cm.index;
            const afterClass = content.slice(classStart, classStart + 3000);
            const methodRe = /(?:async\s+)?(\w+)\s*\([^)]*\)\s*\{/g;
            const methods = [];
            let mm;
            while ((mm = methodRe.exec(afterClass)) !== null) {
                if (mm[1] !== className && mm[1] !== 'constructor' && !mm[1].startsWith('_'))
                    methods.push(mm[1]);
                if (methods.length >= 30) break;
            }
            classes.push({ name: className, bases, methods, doc: null });
        }

        // Python standalone functions (not indented = module-level)
        const pyFnRe = /^(?:def|async\s+def)\s+(\w+)\s*\(([^)]*)\)/gm;
        let fm;
        while ((fm = pyFnRe.exec(content)) !== null) {
            if (fm[1].startsWith('_') && fm[1] !== '__init__') continue;
            const params = fm[2].replace(/\s*=\s*[^,)]+/g, '').split(',').map(p => p.trim()).filter(Boolean);
            standaloneFunctions.push({ name: fm[1], params: params.slice(0, 5) });
        }

        // JS/TS top-level exported functions
        const jsFnRe = /(?:export\s+)?(?:async\s+)?function\s+(\w+)\s*\(([^)]*)\)/g;
        while ((fm = jsFnRe.exec(content)) !== null) {
            const params = fm[2].split(',').map(p => p.trim().split(':')[0].split('=')[0].trim()).filter(Boolean);
            standaloneFunctions.push({ name: fm[1], params: params.slice(0, 5) });
        }

        if (classes.length > 0 || standaloneFunctions.length > 3) {
            fileClasses.push({ filePath: fp, classes, functions: standaloneFunctions.slice(0, 30) });
        }
    }

    if (fileClasses.length === 0) return null;

    let md = '## Key Classes & Functions\n\n';
    let shown = 0;

    for (const { filePath, classes, functions } of fileClasses) {
        if (shown >= 200) { md += `\n*...and ${fileClasses.length - 200} more files with classes/functions*\n`; break; }

        md += `### \`${filePath}\`\n\n`;

        for (const cls of classes) {
            const bases = cls.bases.length ? ` (${cls.bases.join(', ')})` : '';
            md += `**class ${cls.name}**${bases}\n`;
            if (cls.doc) md += `> ${cls.doc}\n`;
            if (cls.methods.length > 0) {
                md += `- Methods: ${cls.methods.map(m => `\`${m}()\``).join(', ')}\n`;
            }
            md += '\n';
        }

        if (functions.length > 0) {
            md += '**Functions:**\n';
            for (const fn of functions.slice(0, 25)) {
                const params = fn.params.length ? fn.params.join(', ') : '';
                md += `- \`${fn.name}(${params})\`\n`;
            }
            if (functions.length > 25) md += `- ...and ${functions.length - 25} more\n`;
            md += '\n';
        }

        shown++;
    }

    return md.trim();
}

function generateAPIReference(fileContents) {
    const routePatterns = [
        { regex: /(?:app|router|server|bp|blueprint)\.(get|post|put|delete|patch|options|all)\s*\(\s*['"`]([^'"`]+)['"`]/gi, framework: 'Express/Flask' },
        { regex: /@(?:app|blueprint|bp)\s*\.route\s*\(\s*['"]([^'"]+)['"](?:[\s\S]*?methods\s*=\s*\[([^\]]+)\])?/gi, framework: 'Flask' },
        { regex: /@(?:app|router)\.(get|post|put|delete|patch)\s*\(\s*['"]([^'"]+)['"]/gi, framework: 'FastAPI' },
        { regex: /path\s*\(\s*['"]([^'"]+)['"]\s*,\s*(\w+)/gi, framework: 'Django' },
        { regex: /@(Get|Post|Put|Delete|Patch|Request)Mapping\s*\(\s*(?:value\s*=\s*)?['"]([^'"]+)['"]/gi, framework: 'Spring' },
        { regex: /(?:http|mux|router)\.(?:HandleFunc|Handle|GET|POST|PUT|DELETE)\s*\(\s*['"]([^'"]+)['"]/gi, framework: 'Go' },
        { regex: /\.add_url_rule\s*\(\s*['"]([^'"]+)['"]/gi, framework: 'Flask' },
    ];

    const routes = [];
    for (const [filePath, content] of fileContents) {
        if (!content) continue;
        for (const { regex, framework } of routePatterns) {
            regex.lastIndex = 0;
            let m;
            while ((m = regex.exec(content)) !== null) {
                if (framework === 'Flask' && m[2]) {
                    const methods = m[2].replace(/['"]/g, '').split(',').map(x => x.trim());
                    for (const method of methods) routes.push({ method: method.toUpperCase(), path: m[1], filePath, framework });
                } else if (framework === 'Django' || framework === 'Go') {
                    routes.push({ method: '*', path: m[1], filePath, framework });
                } else {
                    routes.push({ method: (m[1] || 'GET').toUpperCase(), path: m[2] || m[1], filePath, framework });
                }
            }
        }
    }

    if (routes.length === 0) return null;

    let md = `## API Reference\n\n> ${routes.length} endpoint(s) detected\n\n`;
    md += '| Method | Path | File | Framework |\n|--------|------|------|----------|\n';
    const seen = new Set();
    for (const r of routes) {
        const key = `${r.method}:${r.path}`;
        if (seen.has(key)) continue;
        seen.add(key);
        md += `| \`${r.method}\` | \`${r.path}\` | \`${r.filePath}\` | ${r.framework} |\n`;
    }
    return md;
}

function generateEventSystem(fileContents, filePaths) {
    const events = { topics: new Set(), producers: [], consumers: [], callbacks: [], eventClasses: [] };

    for (const [filePath, content] of fileContents) {
        if (!content) continue;

        // Kafka topics
        const topicPatterns = [
            /['"]([A-Za-z0-9._-]+[-_]topic[A-Za-z0-9._-]*)['"]|TOPIC\s*=\s*['"]([^'"]+)['"]/gi,
            /topic\s*[:=]\s*['"]([^'"]+)['"]/gi,
            /KAFKA_[\w]*TOPIC\s*[:=]\s*['"]?([^'"}\s]+)/gi,
        ];
        for (const re of topicPatterns) {
            re.lastIndex = 0;
            let m;
            while ((m = re.exec(content)) !== null) {
                const topic = m[1] || m[2];
                if (topic && topic.length > 3 && topic.length < 100) events.topics.add(topic);
            }
        }

        // Event classes (Python: class XEvent, XSchema)
        const eventClassRe = /class\s+(\w*(?:Event|Schema|Message|Handler|Callback|Listener)\w*)\s*(?:\(([^)]*)\))?\s*:/g;
        let ec;
        while ((ec = eventClassRe.exec(content)) !== null) {
            events.eventClasses.push({ name: ec[1], bases: ec[2] || '', filePath });
        }

        // Kafka consumer/producer patterns
        if (/KafkaConsumer|consumer|start_kafka_consumer|consume/i.test(content)) {
            const fileName = filePath.split('/').pop();
            if (!events.consumers.some(c => c.file === filePath))
                events.consumers.push({ file: filePath, name: fileName });
        }
        if (/KafkaProducer|producer|start_producer|produce/i.test(content)) {
            const fileName = filePath.split('/').pop();
            if (!events.producers.some(p => p.file === filePath))
                events.producers.push({ file: filePath, name: fileName });
        }

        // Callback functions
        const cbRe = /(?:def|function)\s+(\w*callback\w*|\w*handler\w*|\w*listener\w*)\s*\(/gi;
        let cb;
        while ((cb = cbRe.exec(content)) !== null) {
            events.callbacks.push({ name: cb[1], filePath });
        }
    }

    if (events.topics.size === 0 && events.eventClasses.length === 0 && events.consumers.length === 0) return null;

    let md = '## Event System & Messaging\n\n';

    if (events.topics.size > 0) {
        md += `### Kafka Topics (${events.topics.size})\n\n`;
        for (const topic of [...events.topics].sort()) {
            md += `- \`${topic}\`\n`;
        }
        md += '\n';
    }

    if (events.producers.length > 0) {
        md += `### Producers\n\n`;
        for (const p of events.producers) md += `- \`${p.file}\`\n`;
        md += '\n';
    }

    if (events.consumers.length > 0) {
        md += `### Consumers\n\n`;
        for (const c of events.consumers) md += `- \`${c.file}\`\n`;
        md += '\n';
    }

    if (events.eventClasses.length > 0) {
        md += `### Event Classes & Schemas (${events.eventClasses.length})\n\n`;
        md += '| Class | Inherits | File |\n|-------|----------|------|\n';
        for (const ec of events.eventClasses.slice(0, 150)) {
            md += `| \`${ec.name}\` | ${safeMd(ec.bases) || '—'} | \`${ec.filePath}\` |\n`;
        }
        md += '\n';
    }

    if (events.callbacks.length > 0) {
        md += `### Event Callbacks & Handlers (${events.callbacks.length})\n\n`;
        for (const cb of events.callbacks.slice(0, 80)) {
            md += `- \`${cb.name}()\` in \`${cb.filePath}\`\n`;
        }
    }

    return md.trim();
}

function generateDBSchemas(fileContents, filePaths) {
    const models = [];

    for (const [filePath, content] of fileContents) {
        if (!content) continue;

        // Broad class-based model detection (any class in models/ or dbs/ directory, or inheriting common base names)
        const classRe = /class\s+(\w+)\s*\(([^)]*)\)\s*:/g;
        let cm;
        while ((cm = classRe.exec(content)) !== null) {
            const name = cm[1];
            const bases = cm[2].trim();

            // Detect if this is a model class
            const isModelDir = /models?\/|dbs?\/|entities\/|schemas?\//i.test(filePath);
            const isModelBase = /Model|Base|Entity|Table|Document|Schema|Mixin/i.test(bases);
            const hasColumns = /Column\s*\(|Field\s*\(|CharField|IntegerField|TextField|BooleanField|ForeignKey|relationship/i.test(content.slice(cm.index, cm.index + 2000));

            if ((isModelDir && (isModelBase || hasColumns)) || (isModelBase && hasColumns)) {
                // Extract fields: Column(), Field(), etc.
                const classBlock = content.slice(cm.index, cm.index + 3000);
                const fields = [];

                // SQLAlchemy / Peewee columns
                const colRe = /(\w+)\s*=\s*(?:db\.)?(?:Column|Field|CharField|IntegerField|TextField|BooleanField|FloatField|DateTimeField|ForeignKeyField|relationship)\s*\(([^)]*)\)/g;
                let fm;
                while ((fm = colRe.exec(classBlock)) !== null) {
                    const fieldName = fm[1];
                    const args = fm[2].split(',')[0].trim().replace(/['"]/g, '');
                    fields.push(`${fieldName} (${args || 'Column'})`);
                }

                // Django model fields
                const djangoRe = /(\w+)\s*=\s*models\.(CharField|IntegerField|TextField|BooleanField|FloatField|DateTimeField|ForeignKey|ManyToManyField|OneToOneField|AutoField|BigAutoField|DecimalField|EmailField|URLField|FileField|ImageField|JSONField)\s*\(/g;
                while ((fm = djangoRe.exec(classBlock)) !== null) {
                    fields.push(`${fm[1]} (${fm[2]})`);
                }

                // Simple attribute assignments that look like columns
                const attrRe = /^\s{4}(\w+)\s*=\s*db\.Column\(([^)]*)\)/gm;
                while ((fm = attrRe.exec(classBlock)) !== null) {
                    if (!fields.some(f => f.startsWith(fm[1]))) {
                        fields.push(`${fm[1]} (${fm[2].split(',')[0].trim()})`);
                    }
                }

                const framework = /models\.Model/.test(bases) ? 'Django ORM' :
                    /Base|Mixin/.test(bases) ? 'SQLAlchemy' :
                    /Document/.test(bases) ? 'MongoEngine' :
                    /Model/.test(bases) ? 'ORM Model' : 'Data Model';

                models.push({ name, bases, framework, filePath, fields: fields.slice(0, 50) });
            }
        }

        // Mongoose schemas
        const mongooseRe = /(?:const|let|var)\s+(\w+)\s*=\s*new\s+(?:mongoose\.)?Schema\s*\(\s*\{([^}]+)\}/g;
        while ((cm = mongooseRe.exec(content)) !== null) {
            const fields = [];
            const fieldRe = /(\w+)\s*:/g;
            let fm;
            while ((fm = fieldRe.exec(cm[2])) !== null) fields.push(fm[1]);
            models.push({ name: cm[1], bases: 'mongoose.Schema', framework: 'Mongoose', filePath, fields });
        }

        // Prisma
        const prismaRe = /model\s+(\w+)\s*\{([^}]+)\}/g;
        while ((cm = prismaRe.exec(content)) !== null) {
            const fields = [];
            for (const line of cm[2].split('\n')) {
                const t = line.trim();
                if (!t || t.startsWith('//') || t.startsWith('@@')) continue;
                const parts = t.split(/\s+/);
                if (parts.length >= 2) fields.push(`${parts[0]} (${parts[1]})`);
            }
            models.push({ name: cm[1], bases: '', framework: 'Prisma', filePath, fields });
        }

        // SQL CREATE TABLE
        const sqlRe = /CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?[`"]?(\w+)[`"]?\s*\(([^;]+?)\)/gi;
        while ((cm = sqlRe.exec(content)) !== null) {
            const fields = [];
            for (const col of cm[2].split(',')) {
                const t = col.trim();
                if (/^(PRIMARY|FOREIGN|UNIQUE|INDEX|CONSTRAINT|CHECK)/i.test(t)) continue;
                const parts = t.split(/\s+/);
                if (parts.length >= 2) fields.push(`${parts[0].replace(/[`"]/g, '')} (${parts[1]})`);
            }
            models.push({ name: cm[1], bases: '', framework: 'SQL', filePath, fields });
        }
    }

    // Also detect migration files
    const migrationFiles = filePaths.filter(fp =>
        /migrations?\//i.test(fp) || /alembic\//i.test(fp) || /migrate/i.test(fp.split('/').pop())
    );

    if (models.length === 0 && migrationFiles.length === 0) return null;

    let md = '## Database Schema & Models\n\n';

    if (models.length > 0) {
        md += `> ${models.length} model(s) detected\n\n`;
        for (const model of models) {
            md += `### ${model.name}\n`;
            md += `- **Framework:** ${model.framework}\n`;
            md += `- **File:** \`${model.filePath}\`\n`;
            if (model.bases) md += `- **Inherits:** ${model.bases}\n`;
            if (model.fields && model.fields.length > 0) {
                md += `- **Fields:** ${model.fields.join(', ')}\n`;
            }
            md += '\n';
        }
    }

    if (migrationFiles.length > 0) {
        md += `### Migration Files (${migrationFiles.length})\n\n`;
        for (const mf of migrationFiles.slice(0, 20)) md += `- \`${mf}\`\n`;
        if (migrationFiles.length > 20) md += `- ...and ${migrationFiles.length - 20} more\n`;
    }

    return md.trim();
}

function generateExternalServices(fileContents, filePaths) {
    const services = [];
    const urlPatterns = new Set();

    for (const [filePath, content] of fileContents) {
        if (!content) continue;

        // HTTP calls: requests.get/post, fetch, axios, http.client
        const httpRe = /(?:requests|axios|http|fetch|urllib|aiohttp)\s*\.\s*(get|post|put|delete|patch)\s*\(\s*(?:f?['"`]([^'"`{]+)|(\w+))/gi;
        let m;
        while ((m = httpRe.exec(content)) !== null) {
            const url = m[2] || m[3];
            if (url && url.length > 3) {
                services.push({ method: m[1].toUpperCase(), url: url.slice(0, 100), filePath });
            }
        }

        // Service host/port config references
        const hostRe = /(\w+(?:Service|Host|Endpoint|Url|URI|API|BaseUrl)\w*)\s*[:=]\s*(?:['"]([^'"]+)['"]|os\.environ)/gi;
        while ((m = hostRe.exec(content)) !== null) {
            urlPatterns.add(m[1] + (m[2] ? ` = ${m[2]}` : ''));
        }

        // gRPC, WebSocket, or other protocol patterns
        if (/grpc|\.proto\b/i.test(content)) {
            services.push({ method: 'gRPC', url: 'gRPC service', filePath });
        }
        if (/websocket|ws:\/\/|wss:\/\//i.test(content)) {
            services.push({ method: 'WebSocket', url: 'WebSocket connection', filePath });
        }
    }

    if (services.length === 0 && urlPatterns.size === 0) return null;

    let md = '## External Service Integrations\n\n';

    if (urlPatterns.size > 0) {
        md += `### Service Endpoints & Hosts (${urlPatterns.size})\n\n`;
        for (const p of [...urlPatterns].sort().slice(0, 100)) {
            md += `- \`${p}\`\n`;
        }
        if (urlPatterns.size > 100) md += `- ...and ${urlPatterns.size - 100} more\n`;
        md += '\n';
    }

    if (services.length > 0) {
        // Deduplicate
        const seen = new Set();
        const unique = services.filter(s => {
            const key = `${s.method}:${s.url}`;
            if (seen.has(key)) return false;
            seen.add(key);
            return true;
        });

        md += `### HTTP Calls (${unique.length})\n\n`;
        md += '| Method | URL/Target | File |\n|--------|-----------|------|\n';
        for (const s of unique.slice(0, 30)) {
            md += `| \`${s.method}\` | \`${safeMd(s.url)}\` | \`${s.filePath}\` |\n`;
        }
        if (unique.length > 30) md += `\n*...and ${unique.length - 30} more*\n`;
    }

    return md.trim();
}

function generateDependencies(fileContents, filePaths) {
    const depFiles = {
        'package.json': 'npm', 'requirements.txt': 'pip', 'Pipfile': 'pipenv',
        'pyproject.toml': 'poetry', 'Cargo.toml': 'cargo', 'go.mod': 'go',
        'Gemfile': 'bundler', 'pom.xml': 'maven', 'build.gradle': 'gradle', 'composer.json': 'composer',
    };

    const allDeps = [];
    for (const fp of filePaths) {
        const fileName = fp.split('/').pop();
        const manager = depFiles[fileName];
        if (!manager || fp.includes('node_modules')) continue;
        const content = fileContents.get(fp);
        if (!content) continue;

        if (manager === 'npm') {
            try {
                const pkg = JSON.parse(content);
                for (const [type, deps] of [['production', pkg.dependencies], ['development', pkg.devDependencies], ['peer', pkg.peerDependencies]]) {
                    if (deps) for (const [name, version] of Object.entries(deps)) allDeps.push({ name, version, type, manager });
                }
            } catch (e) { /* ignore */ }
        } else if (manager === 'pip') {
            for (const line of content.split('\n')) {
                const t = line.trim();
                if (!t || t.startsWith('#') || t.startsWith('-')) continue;
                const m = t.match(/^([a-zA-Z0-9_.-]+)\s*([><=!~]+\s*[\d.]+)?/);
                if (m) allDeps.push({ name: m[1], version: m[2] || '*', type: 'production', manager });
            }
        } else if (manager === 'go') {
            const requires = content.match(/require\s*\(([\s\S]*?)\)/);
            if (requires) for (const line of requires[1].split('\n')) {
                const parts = line.trim().split(/\s+/);
                if (parts.length >= 2 && !parts[0].startsWith('//')) allDeps.push({ name: parts[0], version: parts[1], type: 'production', manager });
            }
        } else if (manager === 'cargo') {
            const ds = content.match(/\[dependencies\]([\s\S]*?)(?:\[|$)/);
            if (ds) for (const line of ds[1].split('\n')) {
                const m = line.match(/^(\w[\w-]*)\s*=\s*"?([^"\n]+)"?/);
                if (m) allDeps.push({ name: m[1], version: m[2], type: 'production', manager });
            }
        }
    }

    // Fallback: detect external imports from code when no manifest is indexed
    if (allDeps.length === 0) {
        const externalImports = new Map(); // name -> count
        for (const [, content] of fileContents) {
            if (!content) continue;
            // Python: from X import Y or import X (top-level module only)
            const pyImports = content.matchAll(/(?:from|import)\s+([a-zA-Z_]\w*)/g);
            for (const m of pyImports) {
                const mod = m[1];
                // Skip standard library and local modules
                const stdlib = new Set(['os', 'sys', 'json', 'time', 'datetime', 're', 'math', 'logging', 'pathlib', 'typing', 'collections', 'functools', 'itertools', 'copy', 'io', 'hashlib', 'uuid', 'abc', 'enum', 'dataclasses', 'contextlib', 'operator', 'string', 'struct', 'traceback', 'inspect', 'threading', 'multiprocessing', 'subprocess', 'socket', 'http', 'urllib', 'asyncio', 'concurrent', 'pickle', 'csv', 'xml', 'html', 'email', 'base64', 'binascii', 'codecs', 'locale', 'textwrap', 'unittest', 'pdb', 'profile', 'timeit', 'glob', 'shutil', 'tempfile', 'warnings', 'signal', 'argparse', 'configparser', 'secrets', 'hmac', 'ssl', 'platform', 'random']);
                if (!stdlib.has(mod) && !mod.startsWith('src') && !mod.startsWith('_')) {
                    externalImports.set(mod, (externalImports.get(mod) || 0) + 1);
                }
            }
        }

        if (externalImports.size > 0) {
            // Sort by frequency
            const sorted = [...externalImports.entries()].sort((a, b) => b[1] - a[1]);
            let md = '## Dependencies (Detected from Imports)\n\n';
            md += '> No manifest file (package.json/requirements.txt) was indexed. Dependencies detected from import statements.\n\n';
            md += '| Package | Import Count | Likely Ecosystem |\n|---------|-------------|------------------|\n';

            const pyEcosystem = { 'flask': 'Web Framework', 'django': 'Web Framework', 'fastapi': 'Web Framework', 'sqlalchemy': 'ORM', 'celery': 'Task Queue', 'redis': 'Cache/DB', 'kafka': 'Messaging', 'requests': 'HTTP Client', 'boto3': 'AWS SDK', 'pymongo': 'MongoDB', 'pydantic': 'Validation', 'marshmallow': 'Serialization', 'numpy': 'Scientific', 'pandas': 'Data Analysis', 'pytest': 'Testing', 'aiohttp': 'Async HTTP', 'confluent_kafka': 'Messaging' };

            for (const [mod, count] of sorted.slice(0, 100)) {
                const ecosystem = pyEcosystem[mod.toLowerCase()] || '3rd party';
                md += `| \`${mod}\` | ${count} | ${ecosystem} |\n`;
            }
            return md.trim();
        }
        return null;
    }

    const prodDeps = allDeps.filter(d => d.type === 'production');
    const devDeps = allDeps.filter(d => d.type === 'development');
    const peerDeps = allDeps.filter(d => d.type === 'peer');

    let md = `## Dependencies\n\n> ${allDeps.length} total dependencies\n\n`;
    for (const [label, deps] of [['Production', prodDeps], ['Development', devDeps], ['Peer', peerDeps]]) {
        if (deps.length) {
            md += `### ${label} Dependencies (${deps.length})\n\n`;
            md += '| Package | Version | Manager |\n|---------|---------|--------|\n';
            for (const d of deps) md += `| ${d.name} | ${d.version} | ${d.manager} |\n`;
            md += '\n';
        }
    }
    return md.trim();
}

function generateFileDependencyGraph(importGraph, filePaths) {
    if (!importGraph || importGraph.size === 0) return null;
    const MAX_FILES = 500;
    const fileSet = new Set(filePaths);
    const importedBy = new Map();
    const connectionCount = {};
    filePaths.forEach(fp => { connectionCount[fp] = 0; });

    for (const [fp, data] of importGraph) {
        if (!data?.imports) continue;
        for (const imp of data.imports) {
            for (const target of resolveImportTarget(imp.source, fp, fileSet)) {
                if (!importedBy.has(target)) importedBy.set(target, []);
                importedBy.get(target).push(fp);
                connectionCount[fp] = (connectionCount[fp] || 0) + 1;
                connectionCount[target] = (connectionCount[target] || 0) + 1;
            }
        }
    }

    const ranked = filePaths.filter(fp => (connectionCount[fp] || 0) > 0)
        .sort((a, b) => (connectionCount[b] || 0) - (connectionCount[a] || 0)).slice(0, MAX_FILES);
    if (ranked.length === 0) return null;

    const hubs = ranked.filter(fp => (connectionCount[fp] || 0) >= 5);

    let md = `## File Dependency Graph\n\n> Showing top ${ranked.length} most-connected files\n\n`;

    if (hubs.length > 0) {
        md += '### Hub Files (5+ connections)\n\n';
        for (const fp of hubs) md += `- **\`${fp}\`** — ${connectionCount[fp]} connections\n`;
        md += '\n';
    }

    md += '### Import Relationships\n\n';
    for (const fp of ranked) {
        const data = importGraph.get(fp);
        const imports = [...new Set((data?.imports || []).map(i => resolveImportTarget(i.source, fp, fileSet)).flat().filter(t => t && t !== fp))];
        const importers = [...new Set(importedBy.get(fp) || [])];

        md += `**\`${fp}\`**\n`;
        if (imports.length > 0) md += `  - imports: ${imports.slice(0, 15).map(i => `\`${i}\``).join(', ')}${imports.length > 15 ? ` +${imports.length - 15} more` : ''}\n`;
        if (importers.length > 0) md += `  - imported by: ${importers.slice(0, 15).map(i => `\`${i}\``).join(', ')}${importers.length > 15 ? ` +${importers.length - 15} more` : ''}\n`;
        md += '\n';
    }
    return md.trim();
}

function generateConstantsAndEnums(fileContents, filePaths) {
    const constants = [];

    for (const [filePath, content] of fileContents) {
        if (!content) continue;
        const fileName = filePath.split('/').pop().toLowerCase();
        if (!fileName.includes('constant') && !fileName.includes('config') && !fileName.includes('enum') && !fileName.includes('settings')) continue;

        // Python classes (enums, config classes)
        const classRe = /class\s+(\w+)\s*(?:\(([^)]*)\))?\s*:/g;
        let m;
        while ((m = classRe.exec(content)) !== null) {
            const block = content.slice(m.index, m.index + 2000);
            const attrs = [];
            const attrRe = /^\s{4}(\w+)\s*=\s*(.+)/gm;
            let am;
            while ((am = attrRe.exec(block)) !== null) {
                if (!am[1].startsWith('_')) attrs.push({ name: am[1], value: am[2].trim().slice(0, 60) });
                if (attrs.length >= 15) break;
            }
            if (attrs.length > 0) {
                constants.push({ className: m[1], bases: m[2] || '', filePath, attrs });
            }
        }

        // Module-level constants (UPPER_CASE = value)
        const constRe = /^([A-Z][A-Z0-9_]{2,})\s*=\s*(.+)/gm;
        const moduleConsts = [];
        while ((m = constRe.exec(content)) !== null) {
            moduleConsts.push({ name: m[1], value: m[2].trim().slice(0, 60) });
        }
        if (moduleConsts.length > 0) {
            constants.push({ className: '(module-level)', bases: '', filePath, attrs: moduleConsts.slice(0, 20) });
        }
    }

    if (constants.length === 0) return null;

    let md = '## Constants & Enums\n\n';
    for (const c of constants) {
        md += `### ${c.className}`;
        if (c.bases) md += ` (${c.bases})`;
        md += `\n**File:** \`${c.filePath}\`\n\n`;
        for (const attr of c.attrs) {
            md += `- \`${attr.name}\` = \`${safeMd(attr.value)}\`\n`;
        }
        md += '\n';
    }
    return md.trim();
}

function generateErrorHandling(fileContents, filePaths) {
    const exceptions = [];

    for (const [filePath, content] of fileContents) {
        if (!content) continue;

        // Python custom exceptions
        const pyExRe = /class\s+(\w*(?:Error|Exception|Failure|Fault)\w*)\s*\(([^)]*)\)\s*:/g;
        let m;
        while ((m = pyExRe.exec(content)) !== null) {
            const doc = content.slice(m.index, m.index + 500).match(/:\s*\n\s*(?:"""|''')([^"']+)/);
            exceptions.push({ name: m[1], bases: m[2], filePath, doc: doc ? doc[1].trim().split('\n')[0].slice(0, 100) : null });
        }

        // JS custom errors
        const jsExRe = /class\s+(\w*(?:Error|Exception)\w*)\s+extends\s+(\w+)\s*\{/g;
        while ((m = jsExRe.exec(content)) !== null) {
            exceptions.push({ name: m[1], bases: m[2], filePath, doc: null });
        }
    }

    // Detect error handling patterns
    const tryBlocks = { total: 0, files: new Set() };
    for (const [filePath, content] of fileContents) {
        if (!content) continue;
        const count = (content.match(/\btry\s*[:{]/g) || []).length + (content.match(/\btry:/g) || []).length;
        if (count > 0) { tryBlocks.total += count; tryBlocks.files.add(filePath); }
    }

    if (exceptions.length === 0 && tryBlocks.total === 0) return null;

    let md = '## Error Handling\n\n';

    if (exceptions.length > 0) {
        md += `### Custom Exceptions (${exceptions.length})\n\n`;
        md += '| Exception | Inherits | File | Description |\n|-----------|----------|------|-------------|\n';
        for (const e of exceptions) {
            md += `| \`${e.name}\` | ${e.bases} | \`${e.filePath}\` | ${safeMd(e.doc) || '—'} |\n`;
        }
        md += '\n';
    }

    md += `### Error Handling Stats\n\n`;
    md += `- **try/catch blocks:** ~${tryBlocks.total} across ${tryBlocks.files.size} files\n`;

    return md.trim();
}

function generateCronJobs(fileContents, filePaths) {
    const crons = [];

    for (const [filePath, content] of fileContents) {
        if (!content) continue;
        const fileName = filePath.split('/').pop().toLowerCase();
        if (!fileName.includes('cron') && !fileName.includes('schedule') && !fileName.includes('job') && !fileName.includes('task') && !/cron|schedule|periodic/i.test(content.slice(0, 500))) continue;

        // Cron expressions
        const cronRe = /CRON_EXPRESSION\s*[:=]\s*['"]([^'"]+)['"]|crontab\s*\(\s*['"]([^'"]+)['"]\)|schedule\s*[:=]\s*['"]([^'"]+)['"]/gi;
        let m;
        while ((m = cronRe.exec(content)) !== null) {
            crons.push({ expression: m[1] || m[2] || m[3], filePath, type: 'cron' });
        }

        // Scheduled functions
        const schedRe = /(?:def|function|async\s+def)\s+(\w*(?:cron|schedule|periodic|job|task)\w*)\s*\(/gi;
        while ((m = schedRe.exec(content)) !== null) {
            crons.push({ name: m[1], filePath, type: 'function' });
        }

        // Celery beat / APScheduler
        const celeryRe = /@(?:periodic_task|celery\.task|app\.task)\s*(?:\([^)]*\))?\s*\n\s*(?:def|async\s+def)\s+(\w+)/gi;
        while ((m = celeryRe.exec(content)) !== null) {
            crons.push({ name: m[1], filePath, type: 'celery_task' });
        }
    }

    // Also detect cron-related files
    const cronFiles = filePaths.filter(fp => /crons?\/|schedule|jobs?\//i.test(fp));

    if (crons.length === 0 && cronFiles.length === 0) return null;

    let md = '## Cron Jobs & Scheduled Tasks\n\n';

    if (cronFiles.length > 0) {
        md += `### Cron/Job Files (${cronFiles.length})\n\n`;
        for (const f of cronFiles) md += `- \`${f}\`\n`;
        md += '\n';
    }

    if (crons.length > 0) {
        md += `### Detected Tasks (${crons.length})\n\n`;
        for (const c of crons) {
            if (c.type === 'cron') {
                md += `- **Cron:** \`${c.expression}\` in \`${c.filePath}\`\n`;
            } else {
                md += `- **Function:** \`${c.name}()\` in \`${c.filePath}\`\n`;
            }
        }
    }

    return md.trim();
}

function generateTestStructure(fileContents, filePaths) {
    const testPatterns = /\.(test|spec|e2e|integration)\.[^.]+$|__tests__|test\//i;
    const testFiles = filePaths.filter(fp => testPatterns.test(fp));
    if (testFiles.length === 0) return null;

    const frameworks = new Set();
    let totalTests = 0;

    // --- Categorize test files by type ---
    const e2ePattern = /e2e|cypress|playwright|selenium/i;
    const integPattern = /integration|integ/i;
    const testTypes = { unit: [], integration: [], e2e: [] };

    // Per-file data: test count and describe block names
    const fileTestData = new Map(); // filePath -> { count, describes: string[] }

    for (const tf of testFiles) {
        const content = fileContents.get(tf) || '';

        // Framework detection
        if (/jest|from 'jest'/.test(content)) frameworks.add('Jest');
        if (/mocha|from 'mocha'/.test(content)) frameworks.add('Mocha');
        if (/vitest|from 'vitest'/.test(content)) frameworks.add('Vitest');
        if (/pytest|import pytest/.test(content)) frameworks.add('Pytest');
        if (/unittest/.test(content)) frameworks.add('unittest');
        if (/cypress/.test(content)) frameworks.add('Cypress');
        if (/playwright/.test(content)) frameworks.add('Playwright');

        const testCount = (content.match(/\bit\s*\(/g) || []).length +
            (content.match(/\btest\s*\(/g) || []).length +
            (content.match(/\bdef\s+test_/g) || []).length;
        totalTests += testCount;

        // Extract describe block names (JS/TS) and test class names (Python)
        const describes = [];
        const describeRe = /describe\s*\(\s*['"`]([^'"`]+)['"`]/g;
        let dm;
        while ((dm = describeRe.exec(content)) !== null) {
            describes.push(dm[1]);
        }
        // Python test classes
        const pyClassRe = /class\s+(Test\w+)/g;
        while ((dm = pyClassRe.exec(content)) !== null) {
            describes.push(dm[1]);
        }

        fileTestData.set(tf, { count: testCount, describes });

        // Categorize by type
        if (e2ePattern.test(tf)) {
            testTypes.e2e.push(tf);
        } else if (integPattern.test(tf)) {
            testTypes.integration.push(tf);
        } else {
            testTypes.unit.push(tf);
        }
    }

    if (frameworks.size === 0) {
        for (const tf of testFiles) {
            const c = fileContents.get(tf) || '';
            if (c.includes('describe(') && c.includes('it(')) frameworks.add('Jest/Mocha');
        }
    }

    // --- Build markdown ---
    let md = `## Test Structure\n\n| Metric | Value |\n|--------|-------|\n| Test Files | ${testFiles.length} |\n| Approximate Test Cases | ~${totalTests} |\n`;
    if (frameworks.size > 0) md += `| Frameworks | ${[...frameworks].join(', ')} |\n`;
    md += '\n';

    // --- Test Types table ---
    const typeEntries = [
        ['Unit', testTypes.unit],
        ['Integration', testTypes.integration],
        ['E2E', testTypes.e2e],
    ].filter(([, files]) => files.length > 0);

    if (typeEntries.length > 1 || (typeEntries.length === 1 && typeEntries[0][0] !== 'Unit')) {
        md += '### Test Types\n\n| Type | Files | Test Cases |\n|------|-------|------------|\n';
        for (const [type, files] of typeEntries) {
            const count = files.reduce((sum, fp) => sum + (fileTestData.get(fp)?.count || 0), 0);
            md += `| ${type} | ${files.length} | ~${count} |\n`;
        }
        md += '\n';
    }

    // --- Test Coverage by Area ---
    const areaDirs = {};
    for (const tf of testFiles) {
        const dir = tf.split('/').slice(0, -1).join('/') || '(root)';
        if (!areaDirs[dir]) areaDirs[dir] = [];
        areaDirs[dir].push(tf);
    }

    const areaEntries = Object.entries(areaDirs)
        .map(([dir, files]) => {
            const totalCount = files.reduce((sum, fp) => sum + (fileTestData.get(fp)?.count || 0), 0);
            const allDescribes = files.flatMap(fp => {
                const data = fileTestData.get(fp);
                if (data?.describes?.length > 0) return data.describes;
                // Fallback: derive subject from filename (e.g., Foo.test.js → Foo)
                const name = fp.split('/').pop().replace(/\.(test|spec|e2e|integration)\.[^.]+$/, '');
                return name ? [name] : [];
            });
            return { dir, files, totalCount, describes: [...new Set(allDescribes)] };
        })
        .filter(a => a.describes.length > 0)
        .sort((a, b) => b.totalCount - a.totalCount);

    if (areaEntries.length > 0) {
        md += '### Test Coverage by Area\n\n';
        for (const { dir, files, totalCount, describes } of areaEntries) {
            md += `**\`${dir}/\`** (${files.length} test file${files.length > 1 ? 's' : ''}, ~${totalCount} tests)\n`;
            for (const desc of describes.slice(0, 8)) {
                md += `- ${desc}\n`;
            }
            if (describes.length > 8) md += `- ...and ${describes.length - 8} more\n`;
            md += '\n';
        }
    }

    // --- Test Files by Directory (existing) ---
    const testDirs = {};
    for (const tf of testFiles) {
        const dir = tf.split('/').slice(0, -1).join('/') || '(root)';
        if (!testDirs[dir]) testDirs[dir] = [];
        testDirs[dir].push(tf.split('/').pop());
    }
    md += '### Test Files by Directory\n\n';
    for (const [dir, files] of Object.entries(testDirs).sort()) {
        md += `**\`${dir}/\`** (${files.length})\n`;
        for (const f of files.slice(0, 10)) md += `- ${f}\n`;
        if (files.length > 10) md += `- ...and ${files.length - 10} more\n`;
        md += '\n';
    }
    return md.trim();
}

function generateConfiguration(fileContents, filePaths) {
    const configPatterns = [
        { pattern: /\.env($|\.)/, category: 'Environment Variables' },
        { pattern: /tsconfig\.json$/, category: 'TypeScript' },
        { pattern: /webpack\.config|vite\.config|rollup\.config/, category: 'Build' },
        { pattern: /babel\.config|\.babelrc/, category: 'Build' },
        { pattern: /\.eslintrc|eslint\.config|\.prettierrc/, category: 'Linting/Formatting' },
        { pattern: /jest\.config|vitest\.config|pytest\.ini|setup\.cfg/, category: 'Testing' },
        { pattern: /Dockerfile|docker-compose/, category: 'Docker' },
        { pattern: /\.github\/workflows|\.gitlab-ci|Jenkinsfile|\.circleci/, category: 'CI/CD' },
        { pattern: /nginx\.conf/, category: 'Server' },
        { pattern: /Makefile/, category: 'Build' },
        { pattern: /manifest\.json$/, category: 'App Manifest' },
        { pattern: /config\.py$|config\.js$|settings\.py$/, category: 'App Config' },
    ];

    const configFiles = {};
    for (const fp of filePaths) {
        for (const { pattern, category } of configPatterns) {
            if (pattern.test(fp)) {
                if (!configFiles[category]) configFiles[category] = [];
                configFiles[category].push(fp);
                break;
            }
        }
    }

    const envVars = new Set();
    for (const [, content] of fileContents) {
        if (!content) continue;
        for (const m of content.matchAll(/process\.env\.(\w+)/g)) envVars.add(m[1]);
        for (const m of content.matchAll(/os\.(?:environ|getenv)\s*[\[(]\s*['"](\w+)['"]/g)) envVars.add(m[1]);
        for (const m of content.matchAll(/os\.environ\.get\s*\(\s*['"](\w+)['"]/g)) envVars.add(m[1]);
        for (const m of content.matchAll(/import\.meta\.env\.(\w+)/g)) envVars.add(m[1]);
    }

    if (Object.keys(configFiles).length === 0 && envVars.size === 0) return null;

    let md = '## Configuration & Environment\n\n';
    if (Object.keys(configFiles).length > 0) {
        md += '### Config Files\n\n';
        for (const [category, files] of Object.entries(configFiles).sort()) {
            md += `**${category}:**\n`;
            for (const f of files) md += `- \`${f}\`\n`;
            md += '\n';
        }
    }
    if (envVars.size > 0) {
        const sorted = [...envVars].sort();
        md += `### Environment Variables Referenced (${sorted.length})\n\n`;
        for (const v of sorted.slice(0, 60)) md += `- \`${v}\`\n`;
        if (sorted.length > 60) md += `- ...and ${sorted.length - 60} more\n`;
    }
    return md.trim();
}

function generateFileIndex(filePaths, importGraph, fileContents) {
    const MAX_FILES = 1000;
    let md = '## File Index\n\n';
    if (filePaths.length > MAX_FILES) md += `> Showing ${MAX_FILES} of ${filePaths.length} files\n\n`;

    md += '| File | Language | Description | Exports |\n|------|----------|-------------|--------|\n';
    for (const fp of filePaths.slice(0, MAX_FILES)) {
        const lang = langFromPath(fp) || '—';
        const comment = safeMd(extractFirstComment(fileContents.get(fp)) || '—').slice(0, 80);
        const graphData = importGraph?.get(fp);
        const exports = safeMd((graphData?.exports?.slice(0, 5).map(e => e.name || e).join(', ')) || '—').slice(0, 60);
        md += `| \`${fp}\` | ${lang} | ${comment} | ${exports} |\n`;
    }
    if (filePaths.length > MAX_FILES) md += `\n*...and ${filePaths.length - MAX_FILES} more files*`;
    return md;
}

function resolveImportTarget(source, fromFile, fileSet) {
    if (!source) return [];
    if (!source.startsWith('.') && !source.startsWith('src') && !source.includes('/')) {
        const dotPath = source.replace(/\./g, '/');
        if (fileSet.has(dotPath + '.py')) return [dotPath + '.py'];
        if (fileSet.has(dotPath + '/__init__.py')) return [dotPath + '/__init__.py'];
        return [];
    }
    if (source.startsWith('.')) {
        const fromDir = fromFile.split('/').slice(0, -1).join('/');
        const parts = [...fromDir.split('/'), ...source.split('/')];
        const resolved = [];
        for (const p of parts) {
            if (p === '..') resolved.pop();
            else if (p !== '.' && p !== '') resolved.push(p);
        }
        const base = resolved.join('/');
        for (const ext of ['', '.py', '.js', '.ts', '.jsx', '.tsx', '/index.js', '/index.ts', '/__init__.py']) {
            if (fileSet.has(base + ext)) return [base + ext];
        }
        return [];
    }
    const slashPath = source.replace(/\./g, '/');
    for (const ext of ['', '.py', '.js', '.ts', '.jsx', '.tsx', '/__init__.py', '/index.js']) {
        if (fileSet.has(slashPath + ext)) return [slashPath + ext];
    }
    return [];
}

// ── LLM Enrichment Helpers ──────────────────────────────────────────────────

/**
 * Build a condensed summary of extracted repo data for LLM context.
 * Keeps token count low (~500-800 tokens) while providing enough signal
 * for the LLM to generate meaningful narrative sections.
 */
export function buildExtractedDataSummary(fileContents, importGraph, repoId) {
    const filePaths = [...fileContents.keys()].sort();
    const totalFiles = filePaths.length;

    // Language distribution
    let totalLines = 0;
    const langCount = {};
    for (const fp of filePaths) {
        const lang = langFromPath(fp);
        if (lang) langCount[lang] = (langCount[lang] || 0) + 1;
        totalLines += countLines(fileContents.get(fp));
    }
    const topLangs = Object.entries(langCount).sort((a, b) => b[1] - a[1]).slice(0, 5);

    // Architecture layers
    const layerPatterns = [
        { layer: 'Frontend/UI', re: /components?|views?|pages?|layouts?|popup|ui|frontend|templates?/i },
        { layer: 'Backend/API', re: /routes?|controllers?|api|handlers?|endpoints?|server|backend|middleware/i },
        { layer: 'Services', re: /services?|providers?|managers?|workers?/i },
        { layer: 'Models/Data', re: /models?|entities|types?|schemas?/i },
        { layer: 'Events', re: /events?|consumers?|producers?|callbacks?|listeners?/i },
        { layer: 'Utils', re: /utils?|helpers?|lib|common|shared|tools?/i },
        { layer: 'Tests', re: /tests?|specs?|__tests__|e2e/i },
        { layer: 'Config', re: /config|\.github|docker|scripts?|deploy|ci/i },
    ];
    const layerCounts = {};
    for (const fp of filePaths) {
        const parts = fp.toLowerCase().split('/');
        for (const { layer, re } of layerPatterns) {
            if (parts.some(p => re.test(p))) {
                layerCounts[layer] = (layerCounts[layer] || 0) + 1;
                break;
            }
        }
    }

    // Hub files (most connected)
    const connectionCount = {};
    if (importGraph) {
        for (const [fp, data] of importGraph) {
            if (!data?.imports) continue;
            for (const imp of data.imports) {
                connectionCount[fp] = (connectionCount[fp] || 0) + 1;
            }
        }
    }
    const hubFiles = Object.entries(connectionCount)
        .sort((a, b) => b[1] - a[1])
        .slice(0, 8)
        .map(([fp, count]) => `${fp} (${count} connections)`);

    // Test files
    const testFiles = filePaths.filter(fp => /\.(test|spec|e2e|integration)\.[^.]+$|__tests__|test\//i.test(fp));

    // API routes count
    let apiRouteCount = 0;
    for (const [, content] of fileContents) {
        if (!content) continue;
        apiRouteCount += (content.match(/\.(get|post|put|delete|patch)\s*\(\s*['"]/gi) || []).length;
        apiRouteCount += (content.match(/@(?:app|router)\.(get|post|put|delete|patch)\s*\(/gi) || []).length;
    }

    // Entry points
    const entryPoints = filePaths.filter(fp => {
        const name = fp.split('/').pop().toLowerCase();
        return /\.(js|ts|py|java|go)$/.test(fp) && /^(index|main|app|server|start|entry|manage|wsgi)\./i.test(name);
    }).slice(0, 8);

    // Top-level directories
    const topDirs = [...new Set(filePaths.map(fp => fp.split('/')[0]))].sort().slice(0, 15);

    // Build summary text
    let summary = `Repository: ${repoId}
Files: ${totalFiles} | Lines: ~${totalLines.toLocaleString()}
Languages: ${topLangs.map(([l, c]) => `${l} (${c})`).join(', ')}

Top-level directories: ${topDirs.join(', ')}

Architecture layers:
${Object.entries(layerCounts).map(([layer, count]) => `- ${layer}: ${count} files`).join('\n')}

Entry points: ${entryPoints.length > 0 ? entryPoints.join(', ') : 'none detected'}
API endpoints: ~${apiRouteCount}
Test files: ${testFiles.length} of ${totalFiles} total files`;

    if (hubFiles.length > 0) {
        summary += `\n\nHub files (most imports/connections):\n${hubFiles.map(h => `- ${h}`).join('\n')}`;
    }

    return summary;
}

/**
 * Insert LLM-enriched sections after the header in the RepoInfo markdown.
 * Splits on the first --- separator and inserts the enrichment there.
 */
export function insertAfterHeader(repoInfoMarkdown, enrichedSections) {
    // Update header to reflect AI enrichment
    let markdown = repoInfoMarkdown.replace(
        /> All information is extracted from indexed source code — no AI was used to generate this document\./,
        '> Factual data is extracted from indexed source code. AI-generated insights are included below.'
    );

    const separatorIndex = markdown.indexOf('\n\n---\n\n');
    if (separatorIndex === -1) {
        return markdown + '\n\n---\n\n' + enrichedSections;
    }
    const header = markdown.slice(0, separatorIndex);
    const rest = markdown.slice(separatorIndex);
    return header + '\n\n---\n\n' + enrichedSections + rest;
}
